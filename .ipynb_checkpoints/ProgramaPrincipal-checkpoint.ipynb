{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0f49cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m geodesic\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\__init__.py:176\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tester\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m test\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# use the closest tagged version if possible\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_versions\n\u001b[0;32m    178\u001b[0m v \u001b[38;5;241m=\u001b[39m get_versions()\n\u001b[0;32m    179\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosest-tag\u001b[39m\u001b[38;5;124m\"\u001b[39m, v[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:846\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:941\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1039\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import geopy\n",
    "import psycopg2\n",
    "from psycopg2 import sql, Error\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "import logging\n",
    "import pytz\n",
    "import threading\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def salvar_csv(df_copy, filename):\n",
    "    try:\n",
    "        df = df_copy.copy()\n",
    "        df = df.drop(columns=['FLAG_CICLO', 'NOVO_SEQ'], errors='ignore')  # Remove apenas se existir\n",
    "        df = df.drop_duplicates(['COD', 'REFRESH','DISTANCIA_MINIMA']).reset_index(drop=True)\n",
    "        df = df.reset_index(drop=True)\n",
    "        # Verifica se o arquivo já existe\n",
    "        if os.path.isfile(filename):\n",
    "            # Adiciona dados ao CSV existente sem sobrescrever\n",
    "            df.to_csv(filename, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            # Cria um novo arquivo CSV\n",
    "            df.to_csv(filename, index=False)\n",
    "       \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao salvar dados no arquivo CSV: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def mandar_bd(df):\n",
    "    try:\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        # Inicializa FLAG_CICLO se não existir\n",
    "        if 'FLAG_CICLO' not in df_copy.columns:\n",
    "            df_copy['FLAG_CICLO'] = False  # Inicializa como booleano\n",
    "        \n",
    "        # Marca FLAG_CICLO para SEQ == SEQ_MAX\n",
    "        df_copy['FLAG_CICLO'] = df_copy['SEQ'] == df_copy['SEQ_MAX']\n",
    "        df_copy = df_copy.sort_values(by = ['COD', 'HORA'])\n",
    "        # Lista para armazenar códigos para remoção\n",
    "        codigos_para_remover = []\n",
    "        \n",
    "\n",
    "        # Itera pelo DataFrame\n",
    "        for index, row in df_copy.iterrows():\n",
    "            if row['FLAG_CICLO']:\n",
    "                cod_onibus_ciclo_fechado = row['COD']\n",
    "                df_bd = df[df['COD'] == cod_onibus_ciclo_fechado].copy()\n",
    "                if(len(df_bd) != 1):\n",
    "                    salvar_csv(df_bd, 'dados_onibus_todos.csv')\n",
    "                \n",
    "                # Marca o código para remoção\n",
    "                codigos_para_remover.append(cod_onibus_ciclo_fechado)\n",
    "\n",
    "        # Remove códigos processados do DataFrame\n",
    "        df = df[~df['COD'].isin(codigos_para_remover)]\n",
    "\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(\"Erro no processamento em mandar_bd: %s\", e)\n",
    "        return None\n",
    "def retorna_df_pontos_linha(linha):\n",
    "    url_base = 'https://transporteservico.urbs.curitiba.pr.gov.br/getPontosLinha.php?linha={}&c=821f0'\n",
    "    url = url_base.format(linha)\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        dados_json = response.json()\n",
    "        data = {\n",
    "           \n",
    "            'Nome': [item['NOME'] for item in dados_json],\n",
    "            'Numero': [item['NUM'] for item in dados_json],\n",
    "            'Latitude': [float(item['LAT'].replace(',', '.')) for item in dados_json],\n",
    "            'Longitude': [float(item['LON'].replace(',', '.')) for item in dados_json],\n",
    "            'SEQ': [int(item['SEQ']) for item in dados_json],\n",
    "            'GRUPO': [item['GRUPO'] for item in dados_json],\n",
    "            'Sentido': [item['SENTIDO'] for item in dados_json],\n",
    "            'Tipo': [item['TIPO'] for item in dados_json],\n",
    "            'ID do Itinerario': [int(item['ITINERARY_ID']) for item in dados_json]\n",
    "        }\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['COD'] = linha\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        logging.error(\"Falha ao acessar a pagina: %s\", e)\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "    return df1\n",
    "\n",
    "\n",
    "\n",
    "def calcular_distancia(lat1, lon1, lat2, lon2):\n",
    "    try:\n",
    "        coords_1 = (lat1, lon1)\n",
    "        coords_2 = (lat2, lon2)\n",
    "        distancia = geopy.distance.geodesic(coords_1, coords_2).meters\n",
    "        return distancia\n",
    "    except Exception as e:\n",
    "        logging.error(\"Erro ao calcular distancia: %s\", e)\n",
    "        return None\n",
    "    \n",
    "def encontrar_parada_mais_proxima(df_par, df_onibus):\n",
    "    try:\n",
    "        df_paradas = df_par.copy()\n",
    "        df_codigos_onibus = df_onibus.copy()\n",
    "        \n",
    "        if df_paradas.empty:\n",
    "            logging.warning(\"O DataFrame df_paradas está vazio.\")\n",
    "            return None\n",
    "        \n",
    "        if 'PARADA_MAIS_PROXIMA' not in df_codigos_onibus.columns:\n",
    "            df_codigos_onibus['PARADA_MAIS_PROXIMA'] = 'inicializado'\n",
    "        if 'DISTANCIA_MINIMA' not in df_codigos_onibus.columns:\n",
    "            df_codigos_onibus['DISTANCIA_MINIMA'] = 0.0\n",
    "        if 'SEQ' not in df_codigos_onibus.columns:\n",
    "            df_codigos_onibus['SEQ'] = -1        \n",
    "        if 'SEQ_MAX' not in df_codigos_onibus.columns:\n",
    "            df_codigos_onibus['SEQ_MAX'] = -1        \n",
    "\n",
    "\n",
    "\n",
    "        # Selecionando apenas os dados sobre a linha, contendo todos os sentidos\n",
    "        df_linha = df_paradas[df_paradas['COD'] == df_codigos_onibus['CODIGOLINHA'].iloc[0]]\n",
    "        \n",
    "        # Selecionar apenas a parte do dataframe contendo o sentido in time do ônibus\n",
    "        for index_agora in range(len(df_codigos_onibus)):\n",
    "            \n",
    "            sentido_onibus_agora = df_codigos_onibus['SENT'].iloc[index_agora]\n",
    "            cod_linha = df_codigos_onibus['CODIGOLINHA'].iloc[index_agora]\n",
    "            latitude_onibus_agora = df_codigos_onibus['LAT_IN_TIME'].iloc[index_agora]\n",
    "            longitude_onibus_agora = df_codigos_onibus['LON_IN_TIME'].iloc[index_agora]\n",
    "            \n",
    "            df_ponto_sentido = pd.DataFrame()\n",
    "            \n",
    "            # linha 303\n",
    "            if sentido_onibus_agora == 'IDA' and cod_linha == 303:\n",
    "                df_ponto_sentido = df_linha[df_linha['Sentido'] == 'Terminal Campo Comprido']\n",
    "            elif sentido_onibus_agora == 'VOLTA' and cod_linha == 303:\n",
    "                df_ponto_sentido = df_linha[df_linha['Sentido'] == 'Terminal Centenário']\n",
    "            # linha 203\n",
    "            elif sentido_onibus_agora == 'IDA' and cod_linha == 203:\n",
    "                df_ponto_sentido = df_linha[df_linha['Sentido'] == 'Terminal Sta.Cândida']\n",
    "            elif sentido_onibus_agora == 'VOLTA' and cod_linha == 203:\n",
    "                df_ponto_sentido = df_linha[df_linha['Sentido'] == 'Terminal Capão Raso']\n",
    "            # linha 503 \n",
    "            elif sentido_onibus_agora == 'IDA' and cod_linha == 503:\n",
    "                df_ponto_sentido = df_linha[df_linha['Sentido'] == 'Praça Carlos Gomes']\n",
    "            elif sentido_onibus_agora == 'VOLTA' and cod_linha == 503:\n",
    "                df_ponto_sentido = df_linha[df_linha['Sentido'] == 'Terminal Boqueirão']\n",
    "            # linha 500\n",
    "            elif sentido_onibus_agora == 'IDA' and cod_linha == 500:\n",
    "                df_ponto_sentido = df_linha[df_linha['Sentido'] == 'Praça Carlos Gomes']\n",
    "            elif sentido_onibus_agora == 'VOLTA' and cod_linha == 500:\n",
    "                df_ponto_sentido = df_linha[df_linha['Sentido'] == 'Terminal Boqueirão']\n",
    "            # linha 250\n",
    "            elif sentido_onibus_agora == 'VOLTA' and cod_linha == 250:\n",
    "\n",
    "                df_ponto_sentido = df_linha.loc[df_linha['Sentido'] == 'Terminal Santa Cândida']\n",
    "                df_ponto_sentido = df_ponto_sentido.sort_values(by='SEQ')\n",
    "                df_ponto_sentido = df_ponto_sentido.reset_index(drop=True)\n",
    "                df_ponto_sentido = df_ponto_sentido[df_ponto_sentido['ID do Itinerario'] == 14454].reset_index(drop=True)              \n",
    "                \n",
    "            elif sentido_onibus_agora == 'IDA' and cod_linha == 250:\n",
    "                \n",
    "                df_ponto_sentido = df_linha.loc[df_linha['Sentido'] == 'Terminal Pinheirinho']\n",
    "                df_ponto_sentido = df_ponto_sentido.sort_values(by='SEQ')\n",
    "                df_ponto_sentido = df_ponto_sentido.reset_index(drop=True)\n",
    "                df_ponto_sentido = df_ponto_sentido[df_ponto_sentido['ID do Itinerario'] == 14453].reset_index(drop=True) \n",
    "\n",
    "            if not df_ponto_sentido.empty:\n",
    "                distancias = df_ponto_sentido.apply(lambda row: calcular_distancia(\n",
    "                    latitude_onibus_agora, longitude_onibus_agora, row['Latitude'], row['Longitude']), axis=1)\n",
    "                \n",
    "                index_parada_mais_proxima = distancias.idxmin()\n",
    "                \n",
    "                distancia_minima = distancias.min()  # Menor distância encontrada\n",
    "                \n",
    "                nome_parada_mais_proxima = df_ponto_sentido.loc[index_parada_mais_proxima, 'Nome']\n",
    "                \n",
    "                mapeamento = dict(zip(df_ponto_sentido['Nome'], df_ponto_sentido['SEQ']))\n",
    "                \n",
    "                df_codigos_onibus.at[index_agora, 'PARADA_MAIS_PROXIMA'] = nome_parada_mais_proxima\n",
    "                df_codigos_onibus.at[index_agora, 'SEQ'] = mapeamento[nome_parada_mais_proxima]\n",
    "                df_codigos_onibus.at[index_agora, 'SEQ_MAX'] = df_ponto_sentido['SEQ'].max()\n",
    "                df_codigos_onibus.at[index_agora, 'DISTANCIA_MINIMA'] = distancia_minima\n",
    "\n",
    "\n",
    "        return df_codigos_onibus\n",
    "    except KeyError as ke:\n",
    "        logging.error(\"Chave não encontrada: %s\", ke)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(\"Erro ao encontrar parada mais próxima: %s\", e)\n",
    "        return None\n",
    "\n",
    "def manter_menor_distancia(df):\n",
    "    try:\n",
    "        # Função para encontrar a menor distância em cada grupo\n",
    "        def find_min_distance(group):\n",
    "            return group.nsmallest(1, 'DISTANCIA_MINIMA')\n",
    "        \n",
    "        # Aplicar a função a cada grupo\n",
    "        df_menor_distancia = df.groupby(['COD', 'PARADA_MAIS_PROXIMA'], group_keys=False).apply(find_min_distance).reset_index(drop=True)\n",
    "        return df_menor_distancia\n",
    "    except Exception as e:\n",
    "        logging.error(\"Erro ao manter menor distância: %s\", e)\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "    \n",
    "def buscar_e_processar_dados(linha, df_paradas):\n",
    "    url_base = 'https://transporteservico.urbs.curitiba.pr.gov.br/getVeiculos.php?linha={}&c=821f0'.format(linha)\n",
    "    try:  \n",
    "        response = requests.get(url_base)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        timezone_sp = pytz.timezone('America/Sao_Paulo')\n",
    "        hora_online = datetime.now(timezone_sp).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        dados_json = response.json()\n",
    "\n",
    "        # Verificar se a resposta é uma lista e ignorar\n",
    "        if isinstance(dados_json, list):\n",
    "            #logging.info(\"Sem informações disponíveis para a linha %s\", linha)\n",
    "            return None\n",
    "\n",
    "        codigos_onibus = [{\n",
    "            \"COD\": valor['COD'],\n",
    "            \"REFRESH\": valor['REFRESH'],\n",
    "            \"LAT_IN_TIME\": valor['LAT'],\n",
    "            \"LON_IN_TIME\": valor['LON'],\n",
    "            \"CODIGOLINHA\": int(valor['CODIGOLINHA']),\n",
    "            \"TABELA\": valor['TABELA'],\n",
    "            \"SITUACAO\": valor['SITUACAO'],\n",
    "            \"SITUACAO2\": valor['SITUACAO2'],\n",
    "            \"SENT\": valor['SENT'],\n",
    "            \"SENTIDO_IN_TIME\": valor['SENTIDO']\n",
    "        } for chave, valor in dados_json.items()]\n",
    "\n",
    "        df_codigos_onibus = pd.DataFrame(codigos_onibus)\n",
    "\n",
    "        # Remover linhas que não estão em operação\n",
    "        indices_para_remover = df_codigos_onibus[df_codigos_onibus['SITUACAO2'] != 'REALIZANDO ROTA'].index\n",
    "        df_codigos_onibus.drop(index=indices_para_remover, inplace=True)\n",
    "        df_codigos_onibus.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Selecionar um subdataframe contendo os pontos da linha requisitada\n",
    "        if not df_codigos_onibus.empty:\n",
    "            df_pontos = df_paradas.loc[df_paradas['COD'] == df_codigos_onibus['CODIGOLINHA'].iloc[0]]\n",
    "            df_codigos_onibus['HORA'] = hora_online\n",
    "            df_codigos_onibus = encontrar_parada_mais_proxima(df_pontos, df_codigos_onibus)\n",
    "        else:\n",
    "           # logging.warning(\"Nenhum ônibus encontrado em operação para a linha %s\", linha)\n",
    "            return None\n",
    "\n",
    "        return df_codigos_onibus\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        logging.error(\"Falha ao acessar a página: %s\", e)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(\"Erro ao processar dados: %s\", e)\n",
    "        return None\n",
    "\n",
    "      \n",
    "    \n",
    "\n",
    "\n",
    "################################################################################################################################\n",
    "\n",
    "# Caso precise de todas as linhas em operacao de curitiba,  usar:linhas = range(1000)   \n",
    "# o onibus fica distante a media\n",
    "# Lista de números das linhas\n",
    "linhas = [203, 503,250, 303, 500]\n",
    "\n",
    "\n",
    "# Lista para armazenar os DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Laço para chamar a função e armazenar os DataFrames na lista\n",
    "for linha in linhas:\n",
    "    df_parada = retorna_df_pontos_linha(linha)\n",
    "    dfs.append(df_parada)\n",
    "\n",
    "# Concatenar todos os DataFrames\n",
    "df_linhas_concatenado = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df_concatenado = pd.DataFrame()\n",
    "def processar_linha(linha, result_list):\n",
    "    try:\n",
    "        df_result = buscar_e_processar_dados(linha, df_linhas_concatenado)\n",
    "        if df_result is not None and not df_result.empty:\n",
    "            result_list.append(df_result)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao processar linha {linha}: {e}\")\n",
    "i = 0\n",
    "while True:\n",
    "\n",
    "\n",
    "        result_list = []\n",
    "        threads = [threading.Thread(target=processar_linha, args=(linha, result_list)) for linha in linhas]\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "        if result_list:\n",
    "            for df_result in result_list:\n",
    "                df_concatenado = pd.concat([df_concatenado, df_result], ignore_index=True)\n",
    "                df_concatenado = df_concatenado.drop_duplicates(['COD', 'REFRESH']).reset_index(drop=True)\n",
    "                df_concatenado = df_concatenado.sort_values(by=['COD', 'HORA'])\n",
    "                df_concatenado = df_concatenado.reset_index(drop = True)\n",
    "                df_concatenado = mandar_bd(df_concatenado)\n",
    "\n",
    "        # Espera 60 segundos antes da próxima iteração\n",
    "        logging.info('Numero atual da iteracao: %s', i)\n",
    "        i = i + 1\n",
    "        time.sleep(60)\n",
    "   \n",
    "\n",
    "       \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
