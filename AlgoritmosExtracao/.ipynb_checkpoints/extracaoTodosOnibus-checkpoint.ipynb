{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26eead03-2639-4e3d-a8a4-8c5267c75036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 13:28:35,925 - INFO - Removendo duplicatas da tabela onibus...\n"
     ]
    }
   ],
   "source": [
    "import geopy\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from geopy.distance import geodesic\n",
    "import logging\n",
    "import pytz\n",
    "import threading\n",
    "import time\n",
    "import sqlite3\n",
    "\n",
    "# Configuração de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Conectar ao arquivo .db (ele será criado se não existir)\n",
    "conn = sqlite3.connect('dados_onibus.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Criar tabela (se ainda não existir)\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS onibus (\n",
    "        COD INTEGER,\n",
    "        REFRESH TEXT,\n",
    "        LAT_IN_TIME REAL,\n",
    "        LON_IN_TIME REAL,\n",
    "        CODIGOLINHA INTEGER,\n",
    "        ADAPT INTEGER,\n",
    "        TIPO_VEIC INTEGER,\n",
    "        TABELA TEXT,\n",
    "        SITUACAO TEXT,\n",
    "        SITUACAO2 TEXT,\n",
    "        SENT TEXT,\n",
    "        TCOUNT INTEGER,\n",
    "        SENTIDO_IN_TIME TEXT,\n",
    "        HORA TEXT,\n",
    "        FLAG_PROCES INTEGER\n",
    "    )\n",
    "''')\n",
    "conn.commit()\n",
    "\n",
    "# Função para buscar e processar os dados de uma linha de ônibus\n",
    "def buscar_e_processar_dados(linha):\n",
    "    url_base = f'https://transporteservico.urbs.curitiba.pr.gov.br/getVeiculos.php?linha={linha:03}&c=821f0'\n",
    "    try:\n",
    "        response = requests.get(url_base, timeout=20)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        timezone_sp = pytz.timezone('America/Sao_Paulo')\n",
    "        hora_online = datetime.now(timezone_sp).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        dados_json = response.json()\n",
    "\n",
    "        if not dados_json or not isinstance(dados_json, dict):\n",
    "            return None\n",
    "\n",
    "        codigos_onibus = [{\n",
    "            \"COD\": valor['COD'],\n",
    "            \"REFRESH\": valor['REFRESH'],\n",
    "            \"LAT_IN_TIME\": valor['LAT'],\n",
    "            \"LON_IN_TIME\": valor['LON'],\n",
    "            \"CODIGOLINHA\": int(valor['CODIGOLINHA']),\n",
    "            \"ADAPT\": int(valor['ADAPT']),\n",
    "            \"TIPO_VEIC\": int(valor['TIPO_VEIC']),\n",
    "            \"TABELA\": valor['TABELA'],\n",
    "            \"SITUACAO\": valor['SITUACAO'],\n",
    "            \"SITUACAO2\": valor['SITUACAO2'],\n",
    "            \"SENT\": valor['SENT'],\n",
    "            \"TCOUNT\": valor.get('TCOUNT', 0),\n",
    "            \"SENTIDO_IN_TIME\": valor['SENTIDO']\n",
    "        } for chave, valor in dados_json.items()]\n",
    "\n",
    "        df_codigos_onibus = pd.DataFrame(codigos_onibus)\n",
    "        if not df_codigos_onibus.empty:\n",
    "            df_codigos_onibus['HORA'] = hora_online\n",
    "        else:\n",
    "            #logging.warning(\"Nenhum ônibus encontrado para a linha %s\", linha)\n",
    "            return None\n",
    "\n",
    "        return df_codigos_onibus\n",
    "\n",
    "    except requests.Timeout:\n",
    "        #logging.error(\"Timeout: A conexão para a linha %s demorou mais de 10 segundos\", linha)\n",
    "        return None\n",
    "    except requests.RequestException as e:\n",
    "        #logging.error(\"Erro na requisição para a linha %s: %s\", linha, e)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        #logging.error(\"Erro ao processar a linha %s: %s\", linha, e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def carregar_tabela_para_dataframe(nome_tabela, banco_de_dados):\n",
    "    conn = sqlite3.connect(banco_de_dados)\n",
    "    \n",
    "    try:\n",
    "        # Verificar se a tabela existe\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT name FROM sqlite_master WHERE type='table' AND name=?;\n",
    "        \"\"\", (nome_tabela,))\n",
    "        \n",
    "        resultado = cursor.fetchone()\n",
    "\n",
    "        if resultado:\n",
    "            # Se a tabela existe, carregar seus dados para um DataFrame\n",
    "            df = pd.read_sql_query(f\"SELECT * FROM {nome_tabela}\", conn)\n",
    "            return df\n",
    "        else:\n",
    "            # Retornar um DataFrame vazio se a tabela não existir\n",
    "            return pd.DataFrame()  \n",
    "    finally:\n",
    "        conn.close()  # Garantir que a conexão seja fechada\n",
    "\n",
    "# Função para processar cada linha e armazenar os resultados em uma lista\n",
    "def processar_linha(linha, df_linhas, result_list):\n",
    "    df_result = buscar_e_processar_dados(linha)\n",
    "    if df_result is not None:\n",
    "        result_list.append(df_result)\n",
    "# Função para remover duplicatas do banco de dados\n",
    "def remover_duplicatas():\n",
    "    logging.info(\"Removendo duplicatas da tabela onibus...\")\n",
    "\n",
    "    # Remover duplicatas baseando-se no COD e HORA, mantendo a primeira entrada\n",
    "    cursor.execute('''\n",
    "        DELETE FROM onibus\n",
    "        WHERE rowid NOT IN (\n",
    "            SELECT MIN(rowid)\n",
    "            FROM onibus\n",
    "            GROUP BY COD, LAT_IN_TIME, LON_IN_TIME\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "# Função para gravar os dados no banco de dados SQLite\n",
    "def gravar_no_banco(df_result):\n",
    "    for index, row in df_result.iterrows():\n",
    "        cursor.execute('''\n",
    "            INSERT INTO onibus (COD, REFRESH, LAT_IN_TIME, LON_IN_TIME, CODIGOLINHA, ADAPT, TIPO_VEIC, TABELA, \n",
    "                                SITUACAO, SITUACAO2, SENT, TCOUNT, SENTIDO_IN_TIME, HORA, FLAG_PROCES) \n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (\n",
    "            row['COD'], row['REFRESH'], row['LAT_IN_TIME'], row['LON_IN_TIME'], row['CODIGOLINHA'],\n",
    "            row['ADAPT'], row['TIPO_VEIC'], row['TABELA'], row['SITUACAO'], row['SITUACAO2'], \n",
    "            row['SENT'], row['TCOUNT'], row['SENTIDO_IN_TIME'], row['HORA'], 0\n",
    "        ))\n",
    "    conn.commit()\n",
    "        # Remover as linhas que foram inseridas no banco de dados do DataFrame global\n",
    "    global df_concatenado\n",
    "    df_concatenado = df_concatenado.drop(df_result.index).reset_index(drop=True)\n",
    "\n",
    "# Carregar os dados dos pontos da linha\n",
    "df_linhas = carregar_tabela_para_dataframe('onibus','dados_pontos.db')\n",
    "df_linhas['COD'] = df_linhas['COD'].astype(int)\n",
    "# Obter os códigos únicos das linhas\n",
    "linhas_unicas  = df_linhas['COD'].unique()\n",
    "\n",
    "# DataFrame final para armazenar os resultados concatenados\n",
    "df_concatenado = pd.DataFrame()\n",
    "\n",
    "# Função para gerenciar threads e processamento de dados\n",
    "def processar_linhas_com_threads(linhas_unicas, df_linhas):\n",
    "    global df_concatenado\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    # Criar e iniciar threads para cada linha\n",
    "    threads = [\n",
    "        threading.Thread(target=processar_linha, args=(linha, df_linhas, result_list)) \n",
    "        for linha in linhas_unicas\n",
    "    ]\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    # Concatenar resultados e gravar no banco de dados\n",
    "    if result_list:\n",
    "        df_concatenado = pd.concat([df_concatenado] + result_list, ignore_index=True)\n",
    "        gravar_no_banco(df_concatenado)\n",
    "\n",
    "        remover_duplicatas()\n",
    "\n",
    "\n",
    "\n",
    "# Inicializar o processamento com threads\n",
    "try:\n",
    "    processar_linhas_com_threads(linhas_unicas, df_linhas)\n",
    "finally:\n",
    "    # Fechar a conexão com o banco de dados ao final\n",
    "    conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
